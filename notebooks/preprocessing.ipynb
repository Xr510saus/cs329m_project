{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def all_paths_exist(paths: list[str])->bool:\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_DIR_NAME = 'CPP_Files'\n",
    "LABEL_DIR_NAME = 'Labels'\n",
    "\n",
    "file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "proj_dir = os.path.dirname(file_dir)\n",
    "\n",
    "code_dir = f'{proj_dir}/{CODE_DIR_NAME}'\n",
    "label_dir = f'{proj_dir}/{LABEL_DIR_NAME}'\n",
    "\n",
    "if not all_paths_exist([code_dir, label_dir]):\n",
    "    raise Exception(f'Could not find \"{CODE_DIR_NAME}\" and \"{LABEL_DIR_NAME}\" under \"{proj_dir}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['additional_functions', 'function_data']\n"
     ]
    }
   ],
   "source": [
    "file_names = []\n",
    "\n",
    "for _, _, files in os.walk(code_dir):\n",
    "    for file in files:\n",
    "        try:\n",
    "            if file[-4:] == '.cpp':\n",
    "                file_names.append(file[:-4])\n",
    "        except:\n",
    "            # Exceptions likely occur due to the filename being less than 4 chars long,\n",
    "            # so we can skip since they cannot be the code files we're looking for.\n",
    "            continue\n",
    "        \n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataset_dir(new_dir: str, base_path: str = proj_dir)->str:\n",
    "    dir_path = f'{base_path}/{new_dir}'\n",
    "    \n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "        \n",
    "    return dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tree_sitter_cpp as tscpp\n",
    "\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "LINE_DATASET = 'line_dataset'\n",
    "CUTOFF_DATASET = 'cutoff_dataset'\n",
    "AST_DATASET = 'ast_dataset'\n",
    "\n",
    "parser = Parser(Language(tscpp.language()))\n",
    "\n",
    "def create_data_file(dataset_name: str)->None:\n",
    "    dataset_dir = set_dataset_dir(dataset_name)\n",
    "    data_file = f'{dataset_dir}/data.csv'\n",
    "    container = []\n",
    "\n",
    "    for name in file_names:\n",
    "        cpp_file = f'{code_dir}/{name}.cpp'\n",
    "        txt_file = f'{label_dir}/{name}.txt'\n",
    "        \n",
    "        if not all_paths_exist([cpp_file, txt_file]):\n",
    "            raise Exception(f'Could not find {cpp_file} and {txt_file}')\n",
    "        \n",
    "        with (open(cpp_file, 'r') as code, \n",
    "            open(txt_file, 'r') as labels,\n",
    "            open(data_file, 'w') as data_storage):\n",
    "            code_lines = code.read().splitlines()\n",
    "            label_lines = labels.readlines()        \n",
    "            assert(len(code_lines) == len(label_lines))\n",
    "            \n",
    "            for i in range(len(code_lines)):\n",
    "                curr_label = int(label_lines[i])\n",
    "                \n",
    "                if dataset_name == LINE_DATASET:\n",
    "                    curr_line = code_lines[i]\n",
    "                    curr_code_block = '\\t'.join([line.strip() for line in code_lines])\n",
    "                elif dataset_name == CUTOFF_DATASET:\n",
    "                    curr_line = ''\n",
    "                    curr_code_block = '\\t'.join([line.strip() for line in code_lines[:i+1]])\n",
    "                elif dataset_name == AST_DATASET:\n",
    "                    reduced_code_block = [line.strip() for line in code_lines[:i+1]]\n",
    "                    tree = parser.parse(bytes('\\n'.join(reduced_code_block), encoding='utf-8'))\n",
    "                    \n",
    "                    curr_line = str(tree.root_node)\n",
    "                    curr_code_block = '\\t'.join(reduced_code_block)\n",
    "                else:\n",
    "                    raise Exception(f'Dataset name \"{dataset_name}\" unknown.')\n",
    "                \n",
    "                write_str = [curr_line, curr_code_block, curr_label]\n",
    "                container.append(write_str)\n",
    "            \n",
    "    df = pd.DataFrame(container, columns=['line', 'code', 'label'])\n",
    "    df.to_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_file(LINE_DATASET)\n",
    "create_data_file(CUTOFF_DATASET)\n",
    "create_data_file(AST_DATASET)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs329m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
